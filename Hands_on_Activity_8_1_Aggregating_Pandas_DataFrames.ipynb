{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3D+r2j1zKqf0nbpnOPFI7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartinTiong/CPE-311/blob/main/Hands_on_Activity_8_1_Aggregating_Pandas_DataFrames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hands-on Activity 8.1: Aggregating Data with Pandas"
      ],
      "metadata": {
        "id": "l6VL8mgZ3gt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. With the earthquakes.csv file, select all the earthquakes in Japan with a magType of mb and a magnitude of 4.9 or greater.\n",
        "\n",
        "2. Create bins for each full number of magnitude (for example, the first bin is 0-1, the second is 1-2, and so on) with a magType of ml and count how many are in each bin.\n",
        "\n",
        "3. Using the faang.csv file, group by the ticker and resample to monthly frequency. Make the following aggregations:\n",
        "\n",
        "\n",
        "- Mean of the opening price\n",
        "\n",
        "- Maximum of the high price\n",
        "\n",
        "- Minimum of the low price\n",
        "\n",
        "- Mean of the closing price\n",
        "\n",
        "- Sum of the volume traded\n",
        "\n",
        "4. Build a crosstab with the earthquake data between the tsunami column and the magType column. Rather than showing the frequency count, show the maximum\n",
        "magnitude that was observed for each combination. Put the magType along the columns.\n",
        "5. Calculate the rolling 60-day aggregations of OHLC data by ticker for the FAANG data. Use the same aggregations as exercise no. 3.\n",
        "6. Create a pivot table of the FAANG data that compares the stocks. Put the ticker in the rows and show the averages of the OHLC and volume traded data.\n",
        "7.  Calculate the Z-scores for each numeric column of Netflix's data (ticker is NFLX) using apply().\n",
        "8. Add event descriptions:\n",
        "- Create a dataframe with the following three columns: ticker, date, and event. The columns should have the following values:\n",
        "\n",
        "    *   ticker: 'FB'\n",
        "    *   date: ['2018-07-25', '2018-03-19', '2018-03-20']\n",
        "    event: ['Disappointing user growth announced after close.', 'Cambridge\n",
        "- Set the index to ['date', 'ticker']\n",
        "- Merge this data with the FAANG data using an outer join\n",
        "\n",
        "9. Use the transform() method on the FAANG data to represent all the values in terms of the first date in the data. To do so, divide all the values for each ticker by the values\n",
        "for the first date in the data for that ticker. This is referred to as an index, and the data for the first date is the base (https://ec.europa.eu/eurostat/statistics-explained/\n",
        "index.php/ Beginners:Statisticalconcept-Indexandbaseyear). When data is in this format, we can easily see growth over time. Hint: transform() can take a function name."
      ],
      "metadata": {
        "id": "lpjEKipX3r1q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4ew310tR3UAq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faang = pd.read_csv('/content/faang.csv')\n",
        "earthquakes = pd.read_csv('/content/earthquakes.csv')\n",
        "\n",
        "faang['date'] = pd.to_datetime(faang['date'])"
      ],
      "metadata": {
        "id": "2fVckfZU-MQJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered = earthquakes[\n",
        "    (earthquakes[\"place\"].str.contains(\"Japan\", na=False)) &\n",
        "    (earthquakes[\"magType\"] == \"mb\") &\n",
        "    (earthquakes[\"mag\"] >= 4.9)\n",
        "]\n",
        "print(filtered)"
      ],
      "metadata": {
        "id": "0ffgrwf4_tTJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d9eebd9a-e6aa-4602-9d8b-184c473ad74b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      mag magType           time                         place  tsunami  \\\n",
            "1563  4.9      mb  1538977532250  293km ESE of Iwo Jima, Japan        0   \n",
            "2576  5.4      mb  1538697528010    37km E of Tomakomai, Japan        0   \n",
            "3072  4.9      mb  1538579732490     15km ENE of Hasaki, Japan        0   \n",
            "3632  4.9      mb  1538450871260    53km ESE of Hitachi, Japan        0   \n",
            "\n",
            "     parsed_place  \n",
            "1563        Japan  \n",
            "2576        Japan  \n",
            "3072        Japan  \n",
            "3632        Japan  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quakes = earthquakes[earthquakes[\"magType\"] == \"ml\"].copy()\n",
        "\n",
        "\n",
        "bins = np.arange(0, quakes[\"mag\"].max() + 1, 1)\n",
        "quakes[\"mag_bin\"] = pd.cut(quakes[\"mag\"], bins=bins)\n",
        "\n",
        "\n",
        "quakeSS = quakes[\"mag_bin\"].value_counts().sort_index()"
      ],
      "metadata": {
        "id": "AH0t0tq9_7bv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faang[\"date\"] = pd.to_datetime(faang[\"date\"])\n",
        "faang = faang.set_index(\"date\")\n",
        "\n",
        "monthly = (\n",
        "    faang.groupby(\"ticker\")\n",
        "         .resample(\"ME\")\n",
        "         .agg({\n",
        "             \"open\": \"mean\",\n",
        "             \"high\": \"max\",\n",
        "             \"low\": \"min\",\n",
        "             \"close\": \"mean\",\n",
        "             \"volume\": \"sum\"\n",
        "         })\n",
        ")\n",
        "\n",
        "print(monthly)"
      ],
      "metadata": {
        "id": "-5gm6ZuvASuA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ed349684-bb8d-4327-dd7c-bf2bc46ab203"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          open       high        low        close     volume\n",
            "ticker date                                                                 \n",
            "AAPL   2018-01-31   170.714690   176.6782   161.5708   170.699271  659679440\n",
            "       2018-02-28   164.562753   177.9059   147.9865   164.921884  927894473\n",
            "       2018-03-31   172.421381   180.7477   162.4660   171.878919  713727447\n",
            "       2018-04-30   167.332895   176.2526   158.2207   167.286924  666360147\n",
            "       2018-05-31   182.635582   187.9311   162.7911   183.207418  620976206\n",
            "       2018-06-30   186.605843   192.0247   178.7056   186.508652  527624365\n",
            "       2018-07-31   188.065786   193.7650   181.3655   188.179724  393843881\n",
            "       2018-08-31   210.460287   227.1001   195.0999   211.477743  700318837\n",
            "       2018-09-30   220.611742   227.8939   213.6351   220.356353  678972040\n",
            "       2018-10-31   219.489426   231.6645   204.4963   219.137822  789748068\n",
            "       2018-11-30   190.828681   220.6405   169.5328   190.246652  961321947\n",
            "       2018-12-31   164.537405   184.1501   145.9639   163.564732  898917007\n",
            "AMZN   2018-01-31  1301.377143  1472.5800  1170.5100  1309.010952   96371290\n",
            "       2018-02-28  1447.112632  1528.7000  1265.9300  1442.363158  137784020\n",
            "       2018-03-31  1542.160476  1617.5400  1365.2000  1540.367619  130400151\n",
            "       2018-04-30  1475.841905  1638.1000  1352.8800  1468.220476  129945743\n",
            "       2018-05-31  1590.474545  1635.0000  1546.0200  1594.903636   71615299\n",
            "       2018-06-30  1699.088571  1763.1000  1635.0900  1698.823810   85941510\n",
            "       2018-07-31  1786.305714  1880.0500  1678.0600  1784.649048   97629820\n",
            "       2018-08-31  1891.957826  2025.5700  1776.0200  1897.851304   96575676\n",
            "       2018-09-30  1969.239474  2050.5000  1865.0000  1966.077895   94445693\n",
            "       2018-10-31  1799.630870  2033.1900  1476.3600  1782.058261  183228552\n",
            "       2018-11-30  1622.323810  1784.0000  1420.0000  1625.483810  139290208\n",
            "       2018-12-31  1572.922105  1778.3400  1307.0000  1559.443158  154812304\n",
            "FB     2018-01-31   184.364762   190.6600   175.8000   184.962857  495655736\n",
            "       2018-02-28   180.721579   195.3200   167.1800   180.269474  516621991\n",
            "       2018-03-31   173.449524   186.1000   149.0200   173.489524  996232472\n",
            "       2018-04-30   164.163557   177.1000   150.5100   163.810476  751130388\n",
            "       2018-05-31   181.910509   192.7200   170.2300   182.930000  401144183\n",
            "       2018-06-30   194.974067   203.5500   186.4300   195.267619  387265765\n",
            "       2018-07-31   199.332143   218.6200   166.5600   199.967143  652763259\n",
            "       2018-08-31   177.598443   188.3000   170.2700   177.491957  549016789\n",
            "       2018-09-30   164.232895   173.8900   158.8656   164.377368  500468912\n",
            "       2018-10-31   154.873261   165.8800   139.0300   154.187826  622446235\n",
            "       2018-11-30   141.762857   154.1300   126.8500   141.635714  518150415\n",
            "       2018-12-31   137.529474   147.1900   123.0200   137.161053  558786249\n",
            "GOOG   2018-01-31  1127.200952  1186.8900  1045.2300  1130.770476   28738485\n",
            "       2018-02-28  1088.629474  1174.0000   992.5600  1088.206842   42384105\n",
            "       2018-03-31  1096.108095  1177.0500   980.6400  1091.490476   45430049\n",
            "       2018-04-30  1038.415238  1094.1600   990.3700  1035.696190   41773275\n",
            "       2018-05-31  1064.021364  1110.7500  1006.2900  1069.275909   31849196\n",
            "       2018-06-30  1136.396190  1186.2900  1096.0100  1137.626667   32103642\n",
            "       2018-07-31  1183.464286  1273.8900  1093.8000  1187.590476   31953386\n",
            "       2018-08-31  1226.156957  1256.5000  1188.2400  1225.671739   28820379\n",
            "       2018-09-30  1176.878421  1212.9900  1146.9100  1175.808947   28863199\n",
            "       2018-10-31  1116.082174  1209.9600   995.8300  1110.940435   48496167\n",
            "       2018-11-30  1054.971429  1095.5700   996.0200  1056.162381   36735570\n",
            "       2018-12-31  1042.620000  1124.6500   970.1100  1037.420526   40256461\n",
            "NFLX   2018-01-31   231.269286   286.8100   195.4200   232.908095  238377533\n",
            "       2018-02-28   270.873158   297.3600   236.1100   271.443684  184585819\n",
            "       2018-03-31   312.712857   333.9800   275.9000   312.228095  263449491\n",
            "       2018-04-30   309.129529   338.8200   271.2239   307.466190  262064417\n",
            "       2018-05-31   329.779759   356.1000   305.7300   331.536818  142051114\n",
            "       2018-06-30   384.557595   423.2056   352.8200   384.133333  244032001\n",
            "       2018-07-31   380.969090   419.7700   328.0000   381.515238  305487432\n",
            "       2018-08-31   345.409591   376.8085   310.9280   346.257826  213144082\n",
            "       2018-09-30   363.326842   383.2000   335.8300   362.641579  170832156\n",
            "       2018-10-31   340.025348   386.7999   271.2093   335.445652  363589920\n",
            "       2018-11-30   290.643333   332.0499   250.0000   290.344762  257126498\n",
            "       2018-12-31   266.309474   298.7200   231.2300   265.302368  234304628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross = pd.crosstab(\n",
        "    earthquakes[\"tsunami\"],\n",
        "    earthquakes[\"magType\"],\n",
        "    values=earthquakes[\"mag\"],\n",
        "    aggfunc=\"max\"\n",
        ")\n",
        "\n",
        "print(cross)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_cyWcMQqRS8X",
        "outputId": "380527f5-32af-4dfe-9bf7-6f91f84eb822"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "magType   mb  mb_lg    md   mh   ml  ms_20    mw  mwb  mwr  mww\n",
            "tsunami                                                        \n",
            "0        5.6    3.5  4.11  1.1  4.2    NaN  3.83  5.8  4.8  6.0\n",
            "1        6.1    NaN   NaN  NaN  5.1    5.7  4.41  NaN  NaN  7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faang = faang.sort_index()\n",
        "\n",
        "aggregations = (\n",
        "    faang.groupby(\"ticker\")\n",
        "         .rolling(\"60D\")\n",
        "         .agg({\n",
        "             \"open\": \"mean\", \"high\": \"max\", \"low\" : \"min\", \"close\": \"mean\",\"volume\": \"sum\"\n",
        "         })\n",
        ")\n",
        "\n",
        "print(aggregations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0Dyv0KfZRgon",
        "outputId": "1b074747-0e0c-49f2-febf-de52cbcdb9c8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         open      high       low       close       volume\n",
            "ticker date                                                               \n",
            "AAPL   2018-01-02  166.927100  169.0264  166.0442  168.987200   25555934.0\n",
            "       2018-01-03  168.089600  171.2337  166.0442  168.972500   55073833.0\n",
            "       2018-01-04  168.480367  171.2337  166.0442  169.229200   77508430.0\n",
            "       2018-01-05  168.896475  172.0381  166.0442  169.840675  101168448.0\n",
            "       2018-01-08  169.324680  172.2736  166.0442  170.080040  121736214.0\n",
            "...                       ...       ...       ...         ...          ...\n",
            "NFLX   2018-12-24  283.509250  332.0499  233.6800  281.931750  525657894.0\n",
            "       2018-12-26  281.844500  332.0499  231.2300  280.777750  520444588.0\n",
            "       2018-12-27  281.070488  332.0499  231.2300  280.162805  532679805.0\n",
            "       2018-12-28  279.916341  332.0499  231.2300  279.461341  521968250.0\n",
            "       2018-12-31  278.430769  332.0499  231.2300  277.451410  476309676.0\n",
            "\n",
            "[1255 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_table = pd.pivot_table(\n",
        "    faang.reset_index(),\n",
        "    index=\"ticker\",\n",
        "    values=[\"open\", \"high\", \"low\", \"close\", \"volume\"],\n",
        "    aggfunc=\"mean\"\n",
        ")\n",
        "\n",
        "print(pivot_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5Qty2CUbSGo3",
        "outputId": "88c404c0-4756-4579-eb80-4d673db06686"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              close         high          low         open        volume\n",
            "ticker                                                                  \n",
            "AAPL     186.986218   188.906858   185.135729   187.038674  3.402145e+07\n",
            "AMZN    1641.726175  1662.839801  1619.840398  1644.072669  5.649563e+06\n",
            "FB       171.510936   173.615298   169.303110   171.454424  2.768798e+07\n",
            "GOOG    1113.225139  1125.777649  1101.001594  1113.554104  1.742645e+06\n",
            "NFLX     319.290299   325.224583   313.187273   319.620533  1.147030e+07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nflx = faang[faang[\"ticker\"] == \"NFLX\"]\n",
        "\n",
        "z_scores = nflx.select_dtypes(include=np.number).apply(\n",
        "    lambda x: (x - x.mean()) / x.std()\n",
        ")\n",
        "\n",
        "print(z_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Q2eEvWbFTBVV",
        "outputId": "20041e8c-a69a-4697-cc39-a050c7da5ab2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                open      high       low     close    volume\n",
            "date                                                        \n",
            "2018-01-02 -2.500753 -2.516023 -2.410226 -2.416644 -0.088760\n",
            "2018-01-03 -2.380291 -2.423180 -2.285793 -2.335286 -0.507606\n",
            "2018-01-04 -2.296272 -2.406077 -2.234616 -2.323429 -0.959287\n",
            "2018-01-05 -2.275014 -2.345607 -2.202087 -2.234303 -0.782331\n",
            "2018-01-08 -2.218934 -2.295113 -2.143759 -2.192192 -1.038531\n",
            "...              ...       ...       ...       ...       ...\n",
            "2018-12-24 -1.571478 -1.518366 -1.627197 -1.745946 -0.339003\n",
            "2018-12-26 -1.735063 -1.439978 -1.677339 -1.341402  0.517040\n",
            "2018-12-27 -1.407286 -1.417785 -1.495805 -1.302664  0.134868\n",
            "2018-12-28 -1.248762 -1.289018 -1.297285 -1.292137 -0.085164\n",
            "2018-12-31 -1.203817 -1.122354 -1.088531 -1.055420  0.359444\n",
            "\n",
            "[251 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "events = pd.DataFrame({\n",
        "    \"ticker\": [\"FB\", \"FB\", \"FB\"],\n",
        "    \"date\": [\"2018-07-25\", \"2018-03-19\", \"2018-03-20\"],\n",
        "    \"event\": [\n",
        "        \"Disappointing user growth announced after close.\",\n",
        "        \"Cambridge Analytica story\",\n",
        "        \"FTC investigation\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "events[\"date\"] = pd.to_datetime(events[\"date\"])\n",
        "events.set_index([\"date\", \"ticker\"], inplace=True)\n",
        "\n",
        "faang_reset = faang.reset_index().set_index([\"date\", \"ticker\"])\n",
        "\n",
        "merging = faang_reset.merge(events, how=\"outer\", left_index=True, right_index=True)\n",
        "\n",
        "print(merging)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d5yA4NJUTD3u",
        "outputId": "97b6a7eb-6405-4693-e040-2cbc78398883"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        open       high        low      close    volume event\n",
            "date       ticker                                                            \n",
            "2018-01-02 AAPL     166.9271   169.0264   166.0442   168.9872  25555934   NaN\n",
            "           AMZN    1172.0000  1190.0000  1170.5100  1189.0100   2694494   NaN\n",
            "           FB       177.6800   181.5800   177.5500   181.4200  18151903   NaN\n",
            "           GOOG    1048.3400  1066.9400  1045.2300  1065.0000   1237564   NaN\n",
            "           NFLX     196.1000   201.6500   195.4200   201.0700  10966889   NaN\n",
            "...                      ...        ...        ...        ...       ...   ...\n",
            "2018-12-31 AAPL     157.8529   158.6794   155.8117   157.0663  35003466   NaN\n",
            "           AMZN    1510.8000  1520.7600  1487.0000  1501.9700   6954507   NaN\n",
            "           FB       134.4500   134.6400   129.9500   131.0900  24625308   NaN\n",
            "           GOOG    1050.9600  1052.7000  1023.5900  1035.6100   1493722   NaN\n",
            "           NFLX     260.1600   270.1001   260.0000   267.6600  13508920   NaN\n",
            "\n",
            "[1255 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faang_reset = faang.reset_index()\n",
        "\n",
        "q9 = (\n",
        "    faang_reset.groupby(\"ticker\")\n",
        "               .transform(lambda x: x / x.iloc[0] if np.issubdtype(x.dtype, np.number) else x)\n",
        ")\n",
        "\n",
        "# Combine with ticker/date for readability\n",
        "q9[[\"ticker\", \"date\"]] = faang_reset[[\"ticker\", \"date\"]]\n",
        "\n",
        "print(q9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uHULk2-YTSGl",
        "outputId": "9936fc48-c5f9-4115-915e-87c0a355844b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           date      open      high       low     close    volume ticker\n",
            "0    2018-01-02  1.000000  1.000000  1.000000  1.000000  1.000000     FB\n",
            "1    2018-01-02  1.000000  1.000000  1.000000  1.000000  1.000000   AMZN\n",
            "2    2018-01-02  1.000000  1.000000  1.000000  1.000000  1.000000   NFLX\n",
            "3    2018-01-02  1.000000  1.000000  1.000000  1.000000  1.000000   AAPL\n",
            "4    2018-01-02  1.000000  1.000000  1.000000  1.000000  1.000000   GOOG\n",
            "...         ...       ...       ...       ...       ...       ...    ...\n",
            "1250 2018-12-31  1.289078  1.277950  1.270386  1.263211  2.581007   AMZN\n",
            "1251 2018-12-31  0.756697  0.741491  0.731907  0.722577  1.356624     FB\n",
            "1252 2018-12-31  1.326670  1.339450  1.330468  1.331178  1.231791   NFLX\n",
            "1253 2018-12-31  0.945640  0.938785  0.938375  0.929457  1.369681   AAPL\n",
            "1254 2018-12-31  1.002499  0.986653  0.979296  0.972404  1.206986   GOOG\n",
            "\n",
            "[1255 rows x 7 columns]\n"
          ]
        }
      ]
    }
  ]
}